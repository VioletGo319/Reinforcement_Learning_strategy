{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2082083,"sourceType":"datasetVersion","datasetId":1248254}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom gym.utils import seeding\nimport gym\nfrom gym import spaces\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport pickle\n\n# shares normalization factor\n# 100 shares per trade\nHMAX_NORMALIZE = 100\n# initial amount of money we have in our account\nINITIAL_ACCOUNT_BALANCE = 1000000\n# total number of stocks in our portfolio\nSTOCK_DIM = 30\n# transaction fee: 1/1000 reasonable percentage\nTRANSACTION_FEE_PERCENT = 0.001\n\n# turbulence index: 90-150 reasonable threshold\n# TURBULENCE_THRESHOLD = 140\nREWARD_SCALING = 1e-4\n\nclass StockEnvTrade(gym.Env):\n    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n    metadata = {'render.modes': ['human']}\n\n    def __init__(self, df, day=0, turbulence_threshold=140, initial=True, previous_state=None, model_name='', iteration=''):\n        self.day = day\n        self.df = df\n        self.initial = initial\n        self.previous_state = previous_state if previous_state is not None else [INITIAL_ACCOUNT_BALANCE] + [0] * (STOCK_DIM * 2)\n        self.action_space = spaces.Box(low=-1, high=1, shape=(STOCK_DIM,))\n        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(181,))\n        self.data = self.df.loc[self.day,:]\n        self.terminal = False\n        self.turbulence_threshold = turbulence_threshold\n        self.state = [INITIAL_ACCOUNT_BALANCE] + self.data.adjcp.values.tolist() + [0]*STOCK_DIM + self.data.macd.values.tolist() + self.data.rsi.values.tolist() + self.data.cci.values.tolist() + self.data.adx.values.tolist()\n        self.reward = 0\n        self.turbulence = 0\n        self.cost = 0\n        self.trades = 0\n        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n        self.rewards_memory = []\n        self.model_name = model_name\n        self.iteration = iteration\n        self._seed()\n\n    def _sell_stock(self, index, action):\n        if self.turbulence < self.turbulence_threshold:\n            if self.state[index+STOCK_DIM+1] > 0:\n                self.state[0] += self.state[index+1]*min(abs(action), self.state[index+STOCK_DIM+1]) * (1 - TRANSACTION_FEE_PERCENT)\n                self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\n                self.cost += self.state[index+1]*min(abs(action), self.state[index+STOCK_DIM+1]) * TRANSACTION_FEE_PERCENT\n                self.trades += 1\n        else:\n            if self.state[index+STOCK_DIM+1] > 0:\n                self.state[0] += self.state[index+1]*self.state[index+STOCK_DIM+1]* (1 - TRANSACTION_FEE_PERCENT)\n                self.state[index+STOCK_DIM+1] = 0\n                self.cost += self.state[index+1]*self.state[index+STOCK_DIM+1]* TRANSACTION_FEE_PERCENT\n                self.trades += 1\n    \n    def _buy_stock(self, index, action):\n        if self.turbulence < self.turbulence_threshold:\n            available_amount = self.state[0] // self.state[index+1]\n            self.state[0] -= self.state[index+1]*min(available_amount, action)* (1 + TRANSACTION_FEE_PERCENT)\n            self.state[index+STOCK_DIM+1] += min(available_amount, action)\n            self.cost += self.state[index+1]*min(available_amount, action)* TRANSACTION_FEE_PERCENT\n            self.trades += 1\n    \n    def step(self, actions):\n        self.terminal = self.day >= len(self.df.index.unique()) - 1\n        if self.terminal:\n            plt.plot(self.asset_memory, 'r')\n            plt.savefig('/kaggle/working/account_value_trade_{}_{}.png'.format(self.model_name, self.iteration))\n            plt.close()\n            df_total_value = pd.DataFrame(self.asset_memory)\n            df_total_value.to_csv('/kaggle/working/account_value_trade_{}_{}.csv'.format(self.model_name, self.iteration))\n            end_total_asset = self.state[0] + sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n            print(\"previous_total_asset:{}\".format(self.asset_memory[0]))\n            print(\"end_total_asset:{}\".format(end_total_asset))\n            print(\"total_reward:{}\".format(end_total_asset - self.asset_memory[0]))\n            print(\"total_cost: \", self.cost)\n            print(\"total trades: \", self.trades)\n            df_total_value.columns = ['account_value']\n            df_total_value['daily_return'] = df_total_value.pct_change(1)\n            sharpe = (4**0.5)*df_total_value['daily_return'].mean() / df_total_value['daily_return'].std()\n            print(\"Sharpe: \", sharpe)\n            df_rewards = pd.DataFrame(self.rewards_memory)\n            df_rewards.to_csv('/kaggle/working/account_rewards_trade_{}_{}.csv'.format(self.model_name, self.iteration))\n            return self.state, self.reward, self.terminal, {}\n        else:\n            actions = actions * HMAX_NORMALIZE\n            if self.turbulence >= self.turbulence_threshold:\n                actions = np.array([-HMAX_NORMALIZE]*STOCK_DIM)\n            begin_total_asset = self.state[0] + sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n            argsort_actions = np.argsort(actions)\n            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n            for index in sell_index:\n                self._sell_stock(index, actions[index])\n            for index in buy_index:\n                self._buy_stock(index, actions[index])\n            self.day += 1\n            self.data = self.df.loc[self.day,:]\n            self.turbulence = self.data['turbulence'].values[0]\n            self.state = [self.state[0]] + self.data.adjcp.values.tolist() + list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + self.data.macd.values.tolist() + self.data.rsi.values.tolist() + self.data.cci.values.tolist() + self.data.adx.values.tolist()\n            end_total_asset = self.state[0] + sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n            self.asset_memory.append(end_total_asset)\n            self.reward = end_total_asset - begin_total_asset\n            self.rewards_memory.append(self.reward)\n            self.reward = self.reward * REWARD_SCALING\n            return self.state, self.reward, self.terminal, {}\n\n    def reset(self):\n        if self.initial or not self.previous_state:\n            self.state = [INITIAL_ACCOUNT_BALANCE] + self.data.adjcp.values.tolist() + [0]*STOCK_DIM + self.data.macd.values.tolist() + self.data.rsi.values.tolist() + self.data.cci.values.tolist() + self.data.adx.values.tolist()\n            self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n        else:\n            if self.previous_state is None:\n                self.previous_state = [INITIAL_ACCOUNT_BALANCE] + [0] * STOCK_DIM * 2  \n            previous_total_asset = self.previous_state[0] + sum(np.array(self.previous_state[1:(STOCK_DIM+1)])*np.array(self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n            self.asset_memory = [previous_total_asset]\n            self.state = [self.previous_state[0]] + self.data.adjcp.values.tolist() + self.previous_state[(STOCK_DIM+1):(STOCK_DIM*2+1)] + self.data.macd.values.tolist() + self.data.rsi.values.tolist() + self.data.cci.values.tolist() + self.data.adx.values.tolist()\n        self.day = 0\n        self.data = self.df.loc[self.day,:]\n        self.turbulence = 0\n        self.cost = 0\n        self.trades = 0\n        self.terminal = False\n        self.rewards_memory = []\n        return self.state\n\n    def _seed(self, seed=None):\n        self.np_random, seed = seeding.np_random(seed)\n        return [seed]\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-13T04:13:06.527938Z","iopub.execute_input":"2024-05-13T04:13:06.528283Z","iopub.status.idle":"2024-05-13T04:13:06.567209Z","shell.execute_reply.started":"2024-05-13T04:13:06.528259Z","shell.execute_reply":"2024-05-13T04:13:06.566291Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"\n\nclass StockEnvTrain(gym.Env):\n    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n    metadata = {'render.modes': ['human']}\n\n    def __init__(self, df,day = 0):\n        #super(StockEnv, self).__init__()\n        #money = 10 , scope = 1\n        self.day = day\n        self.df = df\n\n        # action_space normalization and shape is STOCK_DIM\n        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \n        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n        # load data from a pandas dataframe\n        self.data = self.df.loc[self.day,:]\n        self.terminal = False             \n        # initalize state\n        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n                      self.data.adjcp.values.tolist() + \\\n                      [0]*STOCK_DIM + \\\n                      self.data.macd.values.tolist() + \\\n                      self.data.rsi.values.tolist() + \\\n                      self.data.cci.values.tolist() + \\\n                      self.data.adx.values.tolist()\n        # initialize reward\n        self.reward = 0\n        self.cost = 0\n        # memorize all the total balance change\n        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n        self.rewards_memory = []\n        self.trades = 0\n        #self.reset()\n        self._seed()\n\n\n    def _sell_stock(self, index, action):\n        # perform sell action based on the sign of the action\n        if self.state[index+STOCK_DIM+1] > 0:\n            #update balance\n            self.state[0] += \\\n            self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n             (1- TRANSACTION_FEE_PERCENT)\n\n            self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\n            self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n             TRANSACTION_FEE_PERCENT\n            self.trades+=1\n        else:\n            pass\n\n    \n    def _buy_stock(self, index, action):\n        # perform buy action based on the sign of the action\n        available_amount = self.state[0] // self.state[index+1]\n        # print('available_amount:{}'.format(available_amount))\n\n        #update balance\n        self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n                          (1+ TRANSACTION_FEE_PERCENT)\n\n        self.state[index+STOCK_DIM+1] += min(available_amount, action)\n\n        self.cost+=self.state[index+1]*min(available_amount, action)* \\\n                          TRANSACTION_FEE_PERCENT\n        self.trades+=1\n        \n    def step(self, actions):\n        # print(self.day)\n        self.terminal = self.day >= len(self.df.index.unique())-1\n        # print(actions)\n\n        if self.terminal:\n            plt.plot(self.asset_memory,'r')\n            plt.savefig('/kaggle/working/account_value_train.png')\n            plt.close()\n            end_total_asset = self.state[0]+ \\\n            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n            \n            #print(\"end_total_asset:{}\".format(end_total_asset))\n            df_total_value = pd.DataFrame(self.asset_memory)\n            df_total_value.to_csv('/kaggle/working/account_value_train.csv')\n            #print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):61]))- INITIAL_ACCOUNT_BALANCE ))\n            #print(\"total_cost: \", self.cost)\n            #print(\"total_trades: \", self.trades)\n            df_total_value.columns = ['account_value']\n            df_total_value['daily_return']=df_total_value.pct_change(1)\n            sharpe = (252**0.5)*df_total_value['daily_return'].mean()/ \\\n                  df_total_value['daily_return'].std()\n            #print(\"Sharpe: \",sharpe)\n            #print(\"=================================\")\n            df_rewards = pd.DataFrame(self.rewards_memory)\n            #df_rewards.to_csv('/kaggle/working/account_rewards_train.csv')\n            \n            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\n            #with open('obs.pkl', 'wb') as f:  \n            #    pickle.dump(self.state, f)\n            \n            return self.state, self.reward, self.terminal,{}\n\n        else:\n            # print(np.array(self.state[1:29]))\n\n            actions = actions * HMAX_NORMALIZE\n            #actions = (actions.astype(int))\n            \n            begin_total_asset = self.state[0]+ \\\n            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n            #print(\"begin_total_asset:{}\".format(begin_total_asset))\n            \n            argsort_actions = np.argsort(actions)\n            \n            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n\n            for index in sell_index:\n                # print('take sell action'.format(actions[index]))\n                self._sell_stock(index, actions[index])\n\n            for index in buy_index:\n                # print('take buy action: {}'.format(actions[index]))\n                self._buy_stock(index, actions[index])\n\n            self.day += 1\n            self.data = self.df.loc[self.day,:]         \n            #load next state\n            # print(\"stock_shares:{}\".format(self.state[29:]))\n            self.state =  [self.state[0]] + \\\n                    self.data.adjcp.values.tolist() + \\\n                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\n                    self.data.macd.values.tolist() + \\\n                    self.data.rsi.values.tolist() + \\\n                    self.data.cci.values.tolist() + \\\n                    self.data.adx.values.tolist()\n            \n            end_total_asset = self.state[0]+ \\\n            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n            self.asset_memory.append(end_total_asset)\n            #print(\"end_total_asset:{}\".format(end_total_asset))\n            \n            self.reward = end_total_asset - begin_total_asset            \n            # print(\"step_reward:{}\".format(self.reward))\n            self.rewards_memory.append(self.reward)\n            \n            self.reward = self.reward*REWARD_SCALING\n\n\n\n        return self.state, self.reward, self.terminal, {}\n\n    def reset(self):\n        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n        self.day = 0\n        self.data = self.df.loc[self.day,:]\n        self.cost = 0\n        self.trades = 0\n        self.terminal = False \n        self.rewards_memory = []\n        #initiate state\n        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n                      self.data.adjcp.values.tolist() + \\\n                      [0]*STOCK_DIM + \\\n                      self.data.macd.values.tolist() + \\\n                      self.data.rsi.values.tolist() + \\\n                      self.data.cci.values.tolist() + \\\n                      self.data.adx.values.tolist() \n        # iteration += 1 \n        return self.state\n    \n    def render(self, mode='human'):\n        return self.state\n\n    def _seed(self, seed=None):\n        self.np_random, seed = seeding.np_random(seed)\n        return [seed]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:30:09.946595Z","iopub.execute_input":"2024-05-13T03:30:09.946938Z","iopub.status.idle":"2024-05-13T03:30:09.979312Z","shell.execute_reply.started":"2024-05-13T03:30:09.946911Z","shell.execute_reply":"2024-05-13T03:30:09.978331Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#env stock validation\n\nclass StockEnvValidation(gym.Env):\n    \"\"\"A stock trading environment for OpenAI gym\"\"\"\n    metadata = {'render.modes': ['human']}\n\n    def __init__(self, df, day = 0, turbulence_threshold=140, iteration=''):\n        #super(StockEnv, self).__init__()\n        #money = 10 , scope = 1\n        self.day = day\n        self.df = df\n        # action_space normalization and shape is STOCK_DIM\n        self.action_space = spaces.Box(low = -1, high = 1,shape = (STOCK_DIM,)) \n        # Shape = 181: [Current Balance]+[prices 1-30]+[owned shares 1-30] \n        # +[macd 1-30]+ [rsi 1-30] + [cci 1-30] + [adx 1-30]\n        self.observation_space = spaces.Box(low=0, high=np.inf, shape = (181,))\n        # load data from a pandas dataframe\n        self.data = self.df.loc[self.day,:]\n        self.terminal = False     \n        self.turbulence_threshold = turbulence_threshold\n        # initalize state\n        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n                      self.data.adjcp.values.tolist() + \\\n                      [0]*STOCK_DIM + \\\n                      self.data.macd.values.tolist() + \\\n                      self.data.rsi.values.tolist() + \\\n                      self.data.cci.values.tolist() + \\\n                      self.data.adx.values.tolist()\n        # initialize reward\n        self.reward = 0\n        self.turbulence = 0\n        self.cost = 0\n        self.trades = 0\n        # memorize all the total balance change\n        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n        self.rewards_memory = []\n        #self.reset()\n        self._seed()\n        \n        self.iteration=iteration\n\n\n    def _sell_stock(self, index, action):\n        # perform sell action based on the sign of the action\n        if self.turbulence<self.turbulence_threshold:\n            if self.state[index+STOCK_DIM+1] > 0:\n                #update balance\n                self.state[0] += \\\n                self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n                 (1- TRANSACTION_FEE_PERCENT)\n                \n                self.state[index+STOCK_DIM+1] -= min(abs(action), self.state[index+STOCK_DIM+1])\n                self.cost +=self.state[index+1]*min(abs(action),self.state[index+STOCK_DIM+1]) * \\\n                 TRANSACTION_FEE_PERCENT\n                self.trades+=1\n            else:\n                pass\n        else:\n            # if turbulence goes over threshold, just clear out all positions \n            if self.state[index+STOCK_DIM+1] > 0:\n                #update balance\n                self.state[0] += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n                              (1- TRANSACTION_FEE_PERCENT)\n                self.state[index+STOCK_DIM+1] =0\n                self.cost += self.state[index+1]*self.state[index+STOCK_DIM+1]* \\\n                              TRANSACTION_FEE_PERCENT\n                self.trades+=1\n            else:\n                pass\n    \n    def _buy_stock(self, index, action):\n        # perform buy action based on the sign of the action\n        if self.turbulence< self.turbulence_threshold:\n            available_amount = self.state[0] // self.state[index+1]\n            # print('available_amount:{}'.format(available_amount))\n            \n            #update balance\n            self.state[0] -= self.state[index+1]*min(available_amount, action)* \\\n                              (1+ TRANSACTION_FEE_PERCENT)\n\n            self.state[index+STOCK_DIM+1] += min(available_amount, action)\n            \n            self.cost+=self.state[index+1]*min(available_amount, action)* \\\n                              TRANSACTION_FEE_PERCENT\n            self.trades+=1\n        else:\n            # if turbulence goes over threshold, just stop buying\n            pass\n        \n    def step(self, actions):\n        # print(self.day)\n        self.terminal = self.day >= len(self.df.index.unique())-1\n        # print(actions)\n\n        if self.terminal:\n            plt.plot(self.asset_memory,'r')\n            plt.savefig('/kaggle/working/account_value_validation_{}.png'.format(self.iteration))\n            plt.close()\n            df_total_value = pd.DataFrame(self.asset_memory)\n            df_total_value.to_csv('/kaggle/working/account_value_validation_{}.csv'.format(self.iteration))\n            end_total_asset = self.state[0]+ \\\n            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n            #print(\"previous_total_asset:{}\".format(self.asset_memory[0]))           \n\n            #print(\"end_total_asset:{}\".format(end_total_asset))\n            #print(\"total_reward:{}\".format(self.state[0]+sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):61]))- self.asset_memory[0] ))\n            #print(\"total_cost: \", self.cost)\n            #print(\"total trades: \", self.trades)\n\n            df_total_value.columns = ['account_value']\n            df_total_value['daily_return']=df_total_value.pct_change(1)\n            sharpe = (4**0.5)*df_total_value['daily_return'].mean()/ \\\n                  df_total_value['daily_return'].std()\n            #print(\"Sharpe: \",sharpe)\n            \n            #df_rewards = pd.DataFrame(self.rewards_memory)\n            #df_rewards.to_csv('/kaggle/working/account_rewards_trade_{}.csv'.format(self.iteration))\n            \n            # print('total asset: {}'.format(self.state[0]+ sum(np.array(self.state[1:29])*np.array(self.state[29:]))))\n            #with open('obs.pkl', 'wb') as f:  \n            #    pickle.dump(self.state, f)\n            \n            return self.state, self.reward, self.terminal,{}\n\n        else:\n            # print(np.array(self.state[1:29]))\n\n            actions = actions * HMAX_NORMALIZE\n            #actions = (actions.astype(int))\n            if self.turbulence>=self.turbulence_threshold:\n                actions=np.array([-HMAX_NORMALIZE]*STOCK_DIM)\n            begin_total_asset = self.state[0]+ \\\n            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n            #print(\"begin_total_asset:{}\".format(begin_total_asset))\n            \n            argsort_actions = np.argsort(actions)\n            \n            sell_index = argsort_actions[:np.where(actions < 0)[0].shape[0]]\n            buy_index = argsort_actions[::-1][:np.where(actions > 0)[0].shape[0]]\n\n            for index in sell_index:\n                # print('take sell action'.format(actions[index]))\n                self._sell_stock(index, actions[index])\n\n            for index in buy_index:\n                # print('take buy action: {}'.format(actions[index]))\n                self._buy_stock(index, actions[index])\n\n            self.day += 1\n            self.data = self.df.loc[self.day,:]         \n            self.turbulence = self.data['turbulence'].values[0]\n            #print(self.turbulence)\n            #load next state\n            # print(\"stock_shares:{}\".format(self.state[29:]))\n            self.state =  [self.state[0]] + \\\n                    self.data.adjcp.values.tolist() + \\\n                    list(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]) + \\\n                    self.data.macd.values.tolist() + \\\n                    self.data.rsi.values.tolist() + \\\n                    self.data.cci.values.tolist() + \\\n                    self.data.adx.values.tolist()\n            \n            end_total_asset = self.state[0]+ \\\n            sum(np.array(self.state[1:(STOCK_DIM+1)])*np.array(self.state[(STOCK_DIM+1):(STOCK_DIM*2+1)]))\n            self.asset_memory.append(end_total_asset)\n            #print(\"end_total_asset:{}\".format(end_total_asset))\n            \n            self.reward = end_total_asset - begin_total_asset            \n            # print(\"step_reward:{}\".format(self.reward))\n            self.rewards_memory.append(self.reward)\n            \n            self.reward = self.reward*REWARD_SCALING\n\n        return self.state, self.reward, self.terminal, {}\n\n    def reset(self):  \n        self.asset_memory = [INITIAL_ACCOUNT_BALANCE]\n        self.day = 0\n        self.data = self.df.loc[self.day,:]\n        self.turbulence = 0\n        self.cost = 0\n        self.trades = 0\n        self.terminal = False \n        #self.iteration=self.iteration\n        self.rewards_memory = []\n        #initiate state\n        self.state = [INITIAL_ACCOUNT_BALANCE] + \\\n                      self.data.adjcp.values.tolist() + \\\n                      [0]*STOCK_DIM + \\\n                      self.data.macd.values.tolist() + \\\n                      self.data.rsi.values.tolist()  + \\\n                      self.data.cci.values.tolist()  + \\\n                      self.data.adx.values.tolist() \n            \n        return self.state\n    \n    def render(self, mode='human',close=False):\n        return self.state\n    \n\n    def _seed(self, seed=None):\n        self.np_random, seed = seeding.np_random(seed)\n        return [seed]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:38:55.769981Z","iopub.execute_input":"2024-05-13T03:38:55.770531Z","iopub.status.idle":"2024-05-13T03:38:55.806626Z","shell.execute_reply.started":"2024-05-13T03:38:55.770499Z","shell.execute_reply":"2024-05-13T03:38:55.805862Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Adjust this path based on the actual structure of your Kaggle datasets\nos.chdir(\"/kaggle/input/trading/\")\n\nfrom env.EnvMultipleStock_train import StockEnvTrain\nfrom env.EnvMultipleStock_validation import StockEnvValidation\nfrom env.EnvMultipleStock_trade import StockEnvTrade\n\n# Installing stable-baselines3 which is compatible with TensorFlow 2.x\n!pip install stable-baselines3\n\n# Importing stable-baselines3 components\nfrom stable_baselines3 import PPO, A2C, DDPG, SAC, TD3\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nfrom stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:39:05.833165Z","iopub.execute_input":"2024-05-13T03:39:05.833501Z","iopub.status.idle":"2024-05-13T03:39:18.059828Z","shell.execute_reply.started":"2024-05-13T03:39:05.833475Z","shell.execute_reply":"2024-05-13T03:39:18.058874Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Requirement already satisfied: stable-baselines3 in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /opt/conda/lib/python3.10/site-packages (from stable-baselines3) (0.29.0)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from stable-baselines3) (1.26.4)\nRequirement already satisfied: torch>=1.13 in /opt/conda/lib/python3.10/site-packages (from stable-baselines3) (2.1.2)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from stable-baselines3) (2.2.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from stable-baselines3) (2.1.4)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from stable-baselines3) (3.7.5)\nRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.9.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->stable-baselines3) (2024.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->stable-baselines3) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->stable-baselines3) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"path = '/kaggle/input/trading/trading.csv'\ndf = pd.read_csv(path)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:20:06.317030Z","iopub.execute_input":"2024-05-13T03:20:06.317362Z","iopub.status.idle":"2024-05-13T03:20:06.554958Z","shell.execute_reply.started":"2024-05-13T03:20:06.317332Z","shell.execute_reply":"2024-05-13T03:20:06.553947Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0  datadate   tic      adjcp       open       high        low  \\\n0           0  20090102  AAPL  12.964286  12.268571  13.005714  12.165714   \n1           1  20090102   AXP  19.330000  18.570000  19.520000  18.400000   \n2           2  20090102    BA  45.250000  42.800000  45.560000  42.780000   \n3           3  20090102   CAT  46.910000  44.910000  46.980000  44.710000   \n4           4  20090102  CSCO  16.960000  16.410000  17.000000  16.250000   \n\n       volume  macd    rsi        cci    adx  turbulence  \n0  26641980.0   0.0  100.0  66.666667  100.0         0.0  \n1  10955620.0   0.0  100.0  66.666667  100.0         0.0  \n2   7010171.0   0.0  100.0  66.666667  100.0         0.0  \n3   7116726.0   0.0    0.0  66.666667  100.0         0.0  \n4  40977480.0   0.0  100.0  66.666667  100.0         0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>datadate</th>\n      <th>tic</th>\n      <th>adjcp</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>volume</th>\n      <th>macd</th>\n      <th>rsi</th>\n      <th>cci</th>\n      <th>adx</th>\n      <th>turbulence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>20090102</td>\n      <td>AAPL</td>\n      <td>12.964286</td>\n      <td>12.268571</td>\n      <td>13.005714</td>\n      <td>12.165714</td>\n      <td>26641980.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>20090102</td>\n      <td>AXP</td>\n      <td>19.330000</td>\n      <td>18.570000</td>\n      <td>19.520000</td>\n      <td>18.400000</td>\n      <td>10955620.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>20090102</td>\n      <td>BA</td>\n      <td>45.250000</td>\n      <td>42.800000</td>\n      <td>45.560000</td>\n      <td>42.780000</td>\n      <td>7010171.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>20090102</td>\n      <td>CAT</td>\n      <td>46.910000</td>\n      <td>44.910000</td>\n      <td>46.980000</td>\n      <td>44.710000</td>\n      <td>7116726.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>20090102</td>\n      <td>CSCO</td>\n      <td>16.960000</td>\n      <td>16.410000</td>\n      <td>17.000000</td>\n      <td>16.250000</td>\n      <td>40977480.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>66.666667</td>\n      <td>100.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"rebalance_window = 63\nvalidation_window = 63","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:20:06.556219Z","iopub.execute_input":"2024-05-13T03:20:06.556539Z","iopub.status.idle":"2024-05-13T03:20:06.561187Z","shell.execute_reply.started":"2024-05-13T03:20:06.556513Z","shell.execute_reply":"2024-05-13T03:20:06.560111Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"unique_trade_date = df[(df.datadate > 20151001)&(df.datadate <= 20200707)].datadate.unique()\nprint(unique_trade_date)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:20:06.562615Z","iopub.execute_input":"2024-05-13T03:20:06.562981Z","iopub.status.idle":"2024-05-13T03:20:06.577440Z","shell.execute_reply.started":"2024-05-13T03:20:06.562950Z","shell.execute_reply":"2024-05-13T03:20:06.576402Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[20151002 20151005 20151006 ... 20200702 20200706 20200707]\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_A2C(env_train, model_name, timesteps=10000):\n    start = time.time()\n    model = A2C('MlpPolicy', env_train, verbose=0)\n    model.learn(total_timesteps=timesteps)\n    end = time.time()\n\n    model.save(f\"/kaggle/working/{model_name}\")\n    print(' - Training time (A2C): ', (end - start) / 60, ' minutes')\n    return model\n\ndef train_ACER(env_train, model_name, timesteps=10000):\n    start = time.time()\n    model = ACER('MlpPolicy', env_train, verbose=0)\n    model.learn(total_timesteps=timesteps)\n    end = time.time()\n\n    model.save(f\"/kaggle/working/{model_name}\")\n    print(' - Training time (A2C): ', (end - start) / 60, ' minutes')\n    return model\n\ndef train_DDPG(env_train, model_name, timesteps=10000):\n    # add the noise objects for DDPG\n    n_actions = env_train.action_space.shape[-1]\n    param_noise = None\n    action_noise = OrnsteinUhlenbeckActionNoise(mean=np.zeros(n_actions), sigma=float(0.5) * np.ones(n_actions))\n\n    start = time.time()\n    model = DDPG('MlpPolicy', env_train,action_noise=action_noise)\n    model.learn(total_timesteps=timesteps)\n    end = time.time()\n\n    model.save(f\"/kaggle/working/{model_name}\")\n    print(' - Training time (DDPG): ', (end-start)/60,' minutes')\n    return model\n\ndef train_PPO(env_train, model_name, timesteps=10000):\n    start = time.time()\n    model = PPO('MlpPolicy', env_train, ent_coef = 0.005, batch_size = 8)\n    \n    model.learn(total_timesteps=timesteps)\n    end = time.time()\n\n    model.save(f\"/kaggle/working/{model_name}\")\n    print(' - Training time (PPO): ', (end - start) / 60, ' minutes')\n    return model\n\ndef train_GAIL(env_train, model_name, timesteps=10000):\n    start = time.time()\n    # generate expert trajectories\n    model = SAC('MLpPolicy', env_train, verbose=1)\n    generate_expert_traj(model, 'expert_model_gail', n_timesteps=100, n_episodes=10)\n\n    # Load dataset\n    dataset = ExpertDataset(expert_path='expert_model_gail.npz', traj_limitation=10, verbose=1)\n    model = GAIL('MLpPolicy', env_train, dataset, verbose=1)\n\n    model.learn(total_timesteps=1000)\n    end = time.time()\n\n    model.save(f\"/kaggle/working/{model_name}\")\n    print(' - Training time (PPO): ', (end - start) / 60, ' minutes')\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:30:56.703701Z","iopub.execute_input":"2024-05-13T04:30:56.704070Z","iopub.status.idle":"2024-05-13T04:30:56.718166Z","shell.execute_reply.started":"2024-05-13T04:30:56.704044Z","shell.execute_reply":"2024-05-13T04:30:56.717239Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def data_split(df,start,end):\n    data = df[(df.datadate >= start) & (df.datadate < end)]\n    data=data.sort_values(['datadate','tic'],ignore_index=True)\n    data.index = data.datadate.factorize()[0]\n    return data\n\ndef get_validation_sharpe(iteration):\n    df_total_value = pd.read_csv('/kaggle/working/account_value_validation_{}.csv'.format(iteration), index_col=0)\n    df_total_value.columns = ['account_value_train']\n    df_total_value['daily_return'] = df_total_value.pct_change(1)\n    sharpe = (4 ** 0.5) * df_total_value['daily_return'].mean() / \\\n             df_total_value['daily_return'].std()\n    return sharpe","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:39:55.078788Z","iopub.execute_input":"2024-05-13T03:39:55.079153Z","iopub.status.idle":"2024-05-13T03:39:55.087758Z","shell.execute_reply.started":"2024-05-13T03:39:55.079125Z","shell.execute_reply":"2024-05-13T03:39:55.086869Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def DRL_prediction(df,\n                   model,\n                   name,\n                   last_state,\n                   iter_num,\n                   unique_trade_date,\n                   rebalance_window,\n                   turbulence_threshold,\n                   initial):\n\n    trade_data = data_split(df, start=unique_trade_date[iter_num - rebalance_window], end=unique_trade_date[iter_num])\n    env_trade = DummyVecEnv([lambda: StockEnvTrade(trade_data,\n                                                   turbulence_threshold=turbulence_threshold,\n                                                   initial=initial,\n                                                   previous_state=last_state,\n                                                   model_name=name,\n                                                   iteration=iter_num)])\n    obs_trade = env_trade.reset()\n\n    for i in range(len(trade_data.index.unique())):\n        action, _states = model.predict(obs_trade)\n        obs_trade, rewards, dones, info = env_trade.step(action)\n        if i == (len(trade_data.index.unique()) - 2):\n            last_state = env_trade.render()\n            \n  # Check if last_state is None before trying to create DataFrame\n    if last_state is None:\n        print(\"No last state available.\")\n    else:\n        # Create DataFrame from last_state if it is not None\n        df_last_state = pd.DataFrame({'last_state': [last_state]})\n        df_last_state.to_csv('/kaggle/working/last_state_{}_{}.csv'.format(name, i), index=False)\n\n    return last_state\n\ndef DRL_validation(model, test_data, test_env, test_obs) -> None:\n    for i in range(len(test_data.index.unique())):\n        action, _states = model.predict(test_obs)\n        test_obs, rewards, dones, info = test_env.step(action)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T03:40:05.217160Z","iopub.execute_input":"2024-05-13T03:40:05.217900Z","iopub.status.idle":"2024-05-13T03:40:05.228221Z","shell.execute_reply.started":"2024-05-13T03:40:05.217870Z","shell.execute_reply":"2024-05-13T03:40:05.227213Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def run_ensemble_strategy(df, unique_trade_date, rebalance_window, validation_window) -> None:\n    last_state_ensemble =last_state_ensemble = [INITIAL_ACCOUNT_BALANCE] + [1] * STOCK_DIM * 2\n    ppo_sharpe_list = []\n    ddpg_sharpe_list = []\n    a2c_sharpe_list = []\n\n    model_use = []\n\n    insample_turbulence = df[(df.datadate<20151000) & (df.datadate>=20090000)]\n    insample_turbulence = insample_turbulence.drop_duplicates(subset=['datadate'])\n    insample_turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, .90)\n\n    start = time.time()\n    for i in range(rebalance_window + validation_window, len(unique_trade_date), rebalance_window):\n        if i - rebalance_window - validation_window == 0:\n            # inital state\n            initial = True\n        else:\n            # previous state\n            initial = False\n\n        # Tuning trubulence index based on historical data\n        # Turbulence lookback window is one quarter\n        end_date_index = df.index[df[\"datadate\"] == unique_trade_date[i - rebalance_window - validation_window]].to_list()[-1]\n        start_date_index = end_date_index - validation_window*30 + 1\n\n        historical_turbulence = df.iloc[start_date_index:(end_date_index + 1), :]\n        historical_turbulence = historical_turbulence.drop_duplicates(subset=['datadate'])\n        historical_turbulence_mean = np.mean(historical_turbulence.turbulence.values)\n\n        if historical_turbulence_mean > insample_turbulence_threshold:\n            # if the mean of the historical data is greater than the 90% quantile of insample turbulence data\n            # then we assume that the current market is volatile,\n            turbulence_threshold = insample_turbulence_threshold\n        else:\n            # if the mean of the historical data is less than the 90% quantile of insample turbulence data\n            # then we tune up the turbulence_threshold, meaning we lower the risk\n            turbulence_threshold = np.quantile(insample_turbulence.turbulence.values, 1)\n            \n        print(\"-\" * 50)\n        print(\" - Turbulence_threshold: \", turbulence_threshold)\n\n        train = data_split(df, start=20090000, end=unique_trade_date[i - rebalance_window - validation_window])\n        env_train = DummyVecEnv([lambda: StockEnvTrain(train)])\n\n        ## validation env\n        validation = data_split(df, start=unique_trade_date[i - rebalance_window - validation_window],\n                                end=unique_trade_date[i - rebalance_window])\n        env_val = DummyVecEnv([lambda: StockEnvValidation(validation,\n                                                          turbulence_threshold=turbulence_threshold,\n                                                          iteration=i)])\n        obs_val = env_val.reset()\n        \n        print(\" - Model training from: \", 20090000, \"to \",\n              unique_trade_date[i - rebalance_window - validation_window])\n        print(\" - A2C Training\")\n        model_a2c = train_A2C(env_train, model_name=\"A2C_30k_dow_{}\".format(i), timesteps=300)\n        print(\" - A2C Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n              unique_trade_date[i - rebalance_window])\n        DRL_validation(model=model_a2c, test_data=validation, test_env=env_val, test_obs=obs_val)\n        sharpe_a2c = get_validation_sharpe(i)\n        print(\" - A2C Sharpe Ratio: \", sharpe_a2c)\n\n        print(\" - PPO Training\")\n        model_ppo = train_PPO(env_train, model_name=\"PPO_100k_dow_{}\".format(i), timesteps=100)\n        print(\" - PPO Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n              unique_trade_date[i - rebalance_window])\n        DRL_validation(model=model_ppo, test_data=validation, test_env=env_val, test_obs=obs_val)\n        sharpe_ppo = get_validation_sharpe(i)\n        print(\" - PPO Sharpe Ratio: \", sharpe_ppo)\n\n        print(\" - DDPG Training\")\n        model_ddpg = train_DDPG(env_train, model_name=\"DDPG_10k_dow_{}\".format(i), timesteps=100)\n        print(\" - DDPG Validation from: \", unique_trade_date[i - rebalance_window - validation_window], \"to \",\n              unique_trade_date[i - rebalance_window])\n        \n        DRL_validation(model=model_ddpg, test_data=validation, test_env=env_val, test_obs=obs_val)\n        sharpe_ddpg = get_validation_sharpe(i)\n\n        ppo_sharpe_list.append(sharpe_ppo)\n        a2c_sharpe_list.append(sharpe_a2c)\n        ddpg_sharpe_list.append(sharpe_ddpg)\n\n        # Model Selection based on sharpe ratio\n        if (sharpe_ppo >= sharpe_a2c) & (sharpe_ppo >= sharpe_ddpg):\n            model_ensemble = model_ppo\n            model_use.append('PPO')\n        elif (sharpe_a2c > sharpe_ppo) & (sharpe_a2c > sharpe_ddpg):\n            model_ensemble = model_a2c\n            model_use.append('A2C')\n        else:\n            model_ensemble = model_ddpg\n            model_use.append('DDPG')\n\n        print(\" - Trading from: \", unique_trade_date[i - rebalance_window], \"to \", unique_trade_date[i])\n        print(\"-\" * 50)\n        last_state_ensemble = DRL_prediction(df=df, model=model_ensemble, name=\"ensemble\",\n                                             last_state=last_state_ensemble, iter_num=i,\n                                             unique_trade_date=unique_trade_date,\n                                             rebalance_window=rebalance_window,\n                                             turbulence_threshold=turbulence_threshold,\n                                             initial=initial)\n        \n    end = time.time()\n    print(\"Ensemble Strategy took: \", (end - start) / 60, \" minutes\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:09:24.506842Z","iopub.execute_input":"2024-05-13T04:09:24.507214Z","iopub.status.idle":"2024-05-13T04:09:24.528361Z","shell.execute_reply.started":"2024-05-13T04:09:24.507184Z","shell.execute_reply":"2024-05-13T04:09:24.527468Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"    run_ensemble_strategy(df=df, \n                          unique_trade_date= unique_trade_date,\n                          rebalance_window = rebalance_window,\n                          validation_window=validation_window)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T04:31:08.959685Z","iopub.execute_input":"2024-05-13T04:31:08.960034Z","iopub.status.idle":"2024-05-13T04:41:34.348727Z","shell.execute_reply.started":"2024-05-13T04:31:08.960007Z","shell.execute_reply":"2024-05-13T04:41:34.347708Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"--------------------------------------------------\n - Turbulence_threshold:  171.09407156310158\n - Model training from:  20090000 to  20151002\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.016562227408091226  minutes\n - A2C Validation from:  20151002 to  20160104\n - A2C Sharpe Ratio:  0.014675693824502357\n - PPO Training\n - Training time (PPO):  0.26415040890375774  minutes\n - PPO Validation from:  20151002 to  20160104\n - PPO Sharpe Ratio:  0.005863890642849013\n - DDPG Training\n - Training time (DDPG):  0.20538955132166545  minutes\n - DDPG Validation from:  20151002 to  20160104\n - Trading from:  20160104 to  20160405\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1047399.0622578731\ntotal_reward:47399.06225787313\ntotal_cost:  1105.8038126342635\ntotal trades:  759\nSharpe:  0.14174830479219247\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  96.08032158358223\n - Model training from:  20090000 to  20160104\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.016786396503448486  minutes\n - A2C Validation from:  20160104 to  20160405\n - A2C Sharpe Ratio:  0.11936655879017097\n - PPO Training\n - Training time (PPO):  0.26499009927113854  minutes\n - PPO Validation from:  20160104 to  20160405\n - PPO Sharpe Ratio:  -0.016156380904851553\n - DDPG Training\n - Training time (DDPG):  0.21184477011362712  minutes\n - DDPG Validation from:  20160104 to  20160405\n - Trading from:  20160405 to  20160705\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:993192.733603079\ntotal_reward:-6807.266396921012\ntotal_cost:  7737.999142269037\ntotal trades:  1646\nSharpe:  -0.021693370533806006\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  171.09407156310158\n - Model training from:  20090000 to  20160405\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.01698166529337565  minutes\n - A2C Validation from:  20160405 to  20160705\n - A2C Sharpe Ratio:  0.04985763620574728\n - PPO Training\n - Training time (PPO):  0.26401337385177615  minutes\n - PPO Validation from:  20160405 to  20160705\n - PPO Sharpe Ratio:  0.04217814934610117\n - DDPG Training\n - Training time (DDPG):  0.22125804821650188  minutes\n - DDPG Validation from:  20160405 to  20160705\n - Trading from:  20160705 to  20161003\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:989204.5249667298\ntotal_reward:-10795.475033270195\ntotal_cost:  7328.5287311768025\ntotal trades:  1600\nSharpe:  -0.05641715499535489\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  171.09407156310158\n - Model training from:  20090000 to  20160705\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.016639522711435952  minutes\n - A2C Validation from:  20160705 to  20161003\n - A2C Sharpe Ratio:  -0.030766682291314768\n - PPO Training\n - Training time (PPO):  0.268160871664683  minutes\n - PPO Validation from:  20160705 to  20161003\n - PPO Sharpe Ratio:  -0.07850385622001146\n - DDPG Training\n - Training time (DDPG):  0.22980987230936686  minutes\n - DDPG Validation from:  20160705 to  20161003\n - Trading from:  20161003 to  20170103\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1060933.9665769811\ntotal_reward:60933.966576981125\ntotal_cost:  1018.591437698212\ntotal trades:  930\nSharpe:  0.3826348899067964\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  171.09407156310158\n - Model training from:  20090000 to  20161003\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.017708202203114826  minutes\n - A2C Validation from:  20161003 to  20170103\n - A2C Sharpe Ratio:  0.49206532069714276\n - PPO Training\n - Training time (PPO):  0.2745556275049845  minutes\n - PPO Validation from:  20161003 to  20170103\n - PPO Sharpe Ratio:  0.3920177567274364\n - DDPG Training\n - Training time (DDPG):  0.23857700030008952  minutes\n - DDPG Validation from:  20161003 to  20170103\n - Trading from:  20170103 to  20170404\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1043543.3674400002\ntotal_reward:43543.36744000018\ntotal_cost:  998.9825599999999\ntotal trades:  992\nSharpe:  0.3209867147086355\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  96.08032158358223\n - Model training from:  20090000 to  20170103\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.018127687772115073  minutes\n - A2C Validation from:  20170103 to  20170404\n - A2C Sharpe Ratio:  0.37525455431490295\n - PPO Training\n - Training time (PPO):  0.2691780845324198  minutes\n - PPO Validation from:  20170103 to  20170404\n - PPO Sharpe Ratio:  0.16311772825792625\n - DDPG Training\n - Training time (DDPG):  0.24799201091130574  minutes\n - DDPG Validation from:  20170103 to  20170404\n - Trading from:  20170404 to  20170705\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1008585.9262871658\ntotal_reward:8585.926287165843\ntotal_cost:  5838.555008672448\ntotal trades:  1096\nSharpe:  0.09555348839989096\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  171.09407156310158\n - Model training from:  20090000 to  20170404\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.017054227987925212  minutes\n - A2C Validation from:  20170404 to  20170705\n - A2C Sharpe Ratio:  0.2362256083138897\n - PPO Training\n - Training time (PPO):  0.26678810914357504  minutes\n - PPO Validation from:  20170404 to  20170705\n - PPO Sharpe Ratio:  0.16634563641972533\n - DDPG Training\n - Training time (DDPG):  0.2563031196594238  minutes\n - DDPG Validation from:  20170404 to  20170705\n - Trading from:  20170705 to  20171003\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1050394.1765600007\ntotal_reward:50394.17656000075\ntotal_cost:  2024.9490800000003\ntotal trades:  853\nSharpe:  0.32954298330373905\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  171.09407156310158\n - Model training from:  20090000 to  20170705\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.01775979995727539  minutes\n - A2C Validation from:  20170705 to  20171003\n - A2C Sharpe Ratio:  0.5188823131043487\n - PPO Training\n - Training time (PPO):  0.2661457379659017  minutes\n - PPO Validation from:  20170705 to  20171003\n - PPO Sharpe Ratio:  0.22596844088550488\n - DDPG Training\n - Training time (DDPG):  0.26235279242197673  minutes\n - DDPG Validation from:  20170705 to  20171003\n - Trading from:  20171003 to  20180103\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1078223.5323531546\ntotal_reward:78223.53235315462\ntotal_cost:  8207.673620126392\ntotal trades:  1558\nSharpe:  0.5505479626327834\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  96.08032158358223\n - Model training from:  20090000 to  20171003\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.01681136687596639  minutes\n - A2C Validation from:  20171003 to  20180103\n - A2C Sharpe Ratio:  0.494659504059884\n - PPO Training\n - Training time (PPO):  0.2666251262029012  minutes\n - PPO Validation from:  20171003 to  20180103\n - PPO Sharpe Ratio:  0.29135959473852613\n - DDPG Training\n - Training time (DDPG):  0.268434743086497  minutes\n - DDPG Validation from:  20171003 to  20180103\n - Trading from:  20180103 to  20180405\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1004119.4234964085\ntotal_reward:4119.423496408504\ntotal_cost:  1953.1170879905446\ntotal trades:  330\nSharpe:  0.047480212730167386\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  96.08032158358223\n - Model training from:  20090000 to  20180103\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.016847928365071613  minutes\n - A2C Validation from:  20180103 to  20180405\n - A2C Sharpe Ratio:  -0.04568454094870651\n - PPO Training\n - Training time (PPO):  0.2632371107737223  minutes\n - PPO Validation from:  20180103 to  20180405\n - PPO Sharpe Ratio:  0.06386903721034068\n - DDPG Training\n - Training time (DDPG):  0.2750851551691691  minutes\n - DDPG Validation from:  20180103 to  20180405\n - Trading from:  20180405 to  20180705\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:977884.6837345366\ntotal_reward:-22115.316265463363\ntotal_cost:  6656.192976891095\ntotal trades:  1103\nSharpe:  -0.16745257567232677\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  96.08032158358223\n - Model training from:  20090000 to  20180405\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.01720150311787923  minutes\n - A2C Validation from:  20180405 to  20180705\n - A2C Sharpe Ratio:  0.013354825952783233\n - PPO Training\n - Training time (PPO):  0.26643014351526895  minutes\n - PPO Validation from:  20180405 to  20180705\n - PPO Sharpe Ratio:  -0.3057763231171007\n - DDPG Training\n - Training time (DDPG):  0.2846088925997416  minutes\n - DDPG Validation from:  20180405 to  20180705\n - Trading from:  20180705 to  20181003\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1016826.5946764599\ntotal_reward:16826.594676459907\ntotal_cost:  6745.731421713878\ntotal trades:  968\nSharpe:  0.1704225223115562\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  96.08032158358223\n - Model training from:  20090000 to  20180705\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.01664732297261556  minutes\n - A2C Validation from:  20180705 to  20181003\n - A2C Sharpe Ratio:  0.11792746112426343\n - PPO Training\n - Training time (PPO):  0.26692943970362343  minutes\n - PPO Validation from:  20180705 to  20181003\n - PPO Sharpe Ratio:  -0.016562824730088004\n - DDPG Training\n - Training time (DDPG):  0.2899098078409831  minutes\n - DDPG Validation from:  20180705 to  20181003\n - Trading from:  20181003 to  20190104\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1016830.874\ntotal_reward:16830.873999999953\ntotal_cost:  1100.038\ntotal trades:  153\nSharpe:  0.3067368688156179\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  171.09407156310158\n - Model training from:  20090000 to  20181003\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.01717563470204671  minutes\n - A2C Validation from:  20181003 to  20190104\n - A2C Sharpe Ratio:  -0.37729731099296093\n - PPO Training\n - Training time (PPO):  0.2789430101712545  minutes\n - PPO Validation from:  20181003 to  20190104\n - PPO Sharpe Ratio:  -0.36906507741040967\n - DDPG Training\n - Training time (DDPG):  0.3011738657951355  minutes\n - DDPG Validation from:  20181003 to  20190104\n - Trading from:  20190104 to  20190405\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1053381.583016004\ntotal_reward:53381.58301600395\ntotal_cost:  10468.953345899643\ntotal trades:  1662\nSharpe:  0.2659148530402895\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  96.08032158358223\n - Model training from:  20090000 to  20190104\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.01779555082321167  minutes\n - A2C Validation from:  20190104 to  20190405\n - A2C Sharpe Ratio:  0.028668940487889732\n - PPO Training\n - Training time (PPO):  0.2710132797559102  minutes\n - PPO Validation from:  20190104 to  20190405\n - PPO Sharpe Ratio:  0.06556549705552368\n - DDPG Training\n - Training time (DDPG):  0.31209014654159545  minutes\n - DDPG Validation from:  20190104 to  20190405\n - Trading from:  20190405 to  20190708\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1005611.5056859982\ntotal_reward:5611.505685998243\ntotal_cost:  952.2232200565021\ntotal trades:  158\nSharpe:  0.45618537954774413\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  96.08032158358223\n - Model training from:  20090000 to  20190405\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.0174986998240153  minutes\n - A2C Validation from:  20190405 to  20190708\n - A2C Sharpe Ratio:  0.15727062670980968\n - PPO Training\n - Training time (PPO):  0.2685620824495951  minutes\n - PPO Validation from:  20190405 to  20190708\n - PPO Sharpe Ratio:  0.1476274876720468\n - DDPG Training\n - Training time (DDPG):  0.3226025660832723  minutes\n - DDPG Validation from:  20190405 to  20190708\n - Trading from:  20190708 to  20191004\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:999368.1992300005\ntotal_reward:-631.8007699995069\ntotal_cost:  2535.263799999999\ntotal trades:  256\nSharpe:  -0.01251995641318924\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  96.08032158358223\n - Model training from:  20090000 to  20190708\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.01816927989323934  minutes\n - A2C Validation from:  20190708 to  20191004\n - A2C Sharpe Ratio:  -0.162873128640501\n - PPO Training\n - Training time (PPO):  0.27118192513783773  minutes\n - PPO Validation from:  20190708 to  20191004\n - PPO Sharpe Ratio:  -0.04868483389758255\n - DDPG Training\n - Training time (DDPG):  0.32786349058151243  minutes\n - DDPG Validation from:  20190708 to  20191004\n - Trading from:  20191004 to  20200106\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:997969.8529999998\ntotal_reward:-2030.14700000023\ntotal_cost:  579.0099999999999\ntotal trades:  80\nSharpe:  -0.34853158641160187\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  96.08032158358223\n - Model training from:  20090000 to  20191004\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.01824939250946045  minutes\n - A2C Validation from:  20191004 to  20200106\n - A2C Sharpe Ratio:  -0.11239309739471691\n - PPO Training\n - Training time (PPO):  0.2716402570406596  minutes\n - PPO Validation from:  20191004 to  20200106\n - PPO Sharpe Ratio:  -0.0970248816478046\n - DDPG Training\n - Training time (DDPG):  0.3332372665405273  minutes\n - DDPG Validation from:  20191004 to  20200106\n - Trading from:  20200106 to  20200406\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:985993.1007988178\ntotal_reward:-14006.899201182183\ntotal_cost:  660.7553013914203\ntotal trades:  163\nSharpe:  -0.46825692604054464\nNo last state available.\n--------------------------------------------------\n - Turbulence_threshold:  96.08032158358223\n - Model training from:  20090000 to  20200106\n - A2C Training\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" - Training time (A2C):  0.018073054154713948  minutes\n - A2C Validation from:  20200106 to  20200406\n - A2C Sharpe Ratio:  -0.44265617330638124\n - PPO Training\n - Training time (PPO):  0.27430207331975304  minutes\n - PPO Validation from:  20200106 to  20200406\n - PPO Sharpe Ratio:  -0.4334503489608362\n - DDPG Training\n - Training time (DDPG):  0.33943023284276325  minutes\n - DDPG Validation from:  20200106 to  20200406\n - Trading from:  20200406 to  20200707\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n","output_type":"stream"},{"name":"stdout","text":"previous_total_asset:1000000\nend_total_asset:1005620.8340000004\ntotal_reward:5620.834000000381\ntotal_cost:  672.097\ntotal trades:  63\nSharpe:  0.27361679616776785\nNo last state available.\nEnsemble Strategy took:  10.422946627934774  minutes\n","output_type":"stream"}]}]}